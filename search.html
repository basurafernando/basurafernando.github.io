<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export (no Abstract/BibTeX)
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array();

	// get data from each row
	entryRowsData = new Array();
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; margin: auto 2em; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { width: 100%; empty-cells: show; border-spacing: 0em 0.2em; margin: 1em 0em; border-style: none; }
th, td { border: 1px gray solid; border-width: 1px 1px; padding: 0.5em; vertical-align: top; text-align: left; }
th { background-color: #efefef; }
td + td, th + th { border-left: none; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.review td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom: 1px gray solid; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>

<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<thead><tr><th width="20%">Author</th><th width="30%">Title</th><th width="5%">Year</th><th width="30%">Journal/Proceedings</th><th width="10%">Reftype</th><th width="5%">DOI/URL</th></tr></thead>
<tbody><tr id="Herath2019" class="entry">
	<td>Herath, S., Fernando, B. and Harandi, M.</td>
	<td>Using Temporal Information for Recognizing Actions from Still Images</td>
	<td>2019</td>
	<td>Pattern Recognition<br/>Vol. 0(0), pp. 1-20&nbsp;</td>
	<td>article</td>
	<td><a href="j.patcog.2019.106989">DOI</a> <a href="https://basurafernando.github.io/papers/PR19.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="SantaCruz2018" class="entry">
	<td>Santa Cruz, R., Fernando, B., Cherian, A. and Gould, S.</td>
	<td>Visual Permutation Learning</td>
	<td>2019</td>
	<td>IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 1-1&nbsp;</td>
	<td>article</td>
	<td><a href="http://doi.org/10.1109/TPAMI.2018.2873701">DOI</a> &nbsp;</td>
</tr>
<tr id="Yu2019" class="entry">
	<td>Yu, X., Fernando, B., Hartley, R. and Porikli, F.</td>
	<td>Semantic Face Hallucination: Super-Resolving Very Low-Resolution Face Images with Supplementary Attributes</td>
	<td>2019</td>
	<td>IEEE transactions on pattern analysis and machine intelligence&nbsp;</td>
	<td>article</td>
	<td><a href="https://ieeexplore.ieee.org/abstract/document/8713923">URL</a>&nbsp;</td>
</tr>
<tr id="Yu2019a" class="entry">
	<td>Yu, X., Porikli, F., Fernando, B. and Hartley, R.</td>
	<td>Hallucinating Unaligned Face Images by Multiscale Transformative Discriminative Networks</td>
	<td>2019</td>
	<td>International Journal of Computer Vision&nbsp;</td>
	<td>article</td>
	<td><a href="http://doi.org/10.1007/s11263-019-01254-5">DOI</a> <a href="https://doi.org/10.1007/s11263-019-01254-5">URL</a>&nbsp;</td>
</tr>
<tr id="Saha2018" class="entry">
	<td>Saha, S.K., Fernando, B., Cuadros, J., Xiao, D. and Kanagasingam, Y.</td>
	<td>Automated Quality Assessment of Colour Fundus Images for Diabetic Retinopathy Screening in Telemedicine</td>
	<td>2018</td>
	<td>Journal of Digital Imaging<br/>Vol. 31(6), pp. 869-878&nbsp;</td>
	<td>article</td>
	<td><a href="https://link.springer.com/article/10.1007/s10278-018-0084-9">URL</a>&nbsp;</td>
</tr>
<tr id="Bilen2017" class="entry">
	<td>Bilen, H., Fernando, B., Gavves, E. and Vedaldi, A.</td>
	<td>Action Recognition with Dynamic Image Networks</td>
	<td>2017</td>
	<td>IEEE transactions on pattern analysis and machine intelligence&nbsp;</td>
	<td>article</td>
	<td><a href="http://arxiv.org/abs/1612.00738">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2017ijcv" class="entry">
	<td>Fernando, B. and Gould, S.</td>
	<td>Discriminatively Learned Hierarchical Rank Pooling Networks</td>
	<td>2017</td>
	<td>International Journal of Computer Vision<br/>Vol. 0(0), pp. 1-22&nbsp;</td>
	<td>article</td>
	<td><a href="https://arxiv.org/abs/1705.10420">URL</a>&nbsp;</td>
</tr>
<tr id="fernando2017rank" class="entry">
	<td>Fernando, B., Gavves, E., Oramas, J., Ghodrati, A. and Tuytelaars, T.</td>
	<td>Rank pooling for action recognition</td>
	<td>2017</td>
	<td>IEEE transactions on pattern analysis and machine intelligence<br/>Vol. 39(4), pp. 773-787&nbsp;</td>
	<td>article</td>
	<td><a href="http://dl.acm.org/citation.cfm?id=3069241">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2015" class="entry">
	<td>Fernando, B., Tommasi, T. and Tuytelaars, T.</td>
	<td>Location recognition over large time lags</td>
	<td>2015</td>
	<td>Computer Vision and Image Understanding<br/>Vol. 139, pp. 21-28&nbsp;</td>
	<td>article</td>
	<td><a href="http://arxiv.org/abs/1409.7556">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2015a" class="entry">
	<td>Fernando, B., Tommasi, T. and Tuytelaars, T.</td>
	<td>Joint cross-domain classification and subspace learning for unsupervised adaptation</td>
	<td>2015</td>
	<td>Pattern Recognition Letters<br/>Vol. 65, pp. 60-66&nbsp;</td>
	<td>article</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/PRL2015.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2014" class="entry">
	<td>Fernando, B., Fromont, E. and Tuytelaars, T.</td>
	<td>Mining mid-level features for image classification</td>
	<td>2014</td>
	<td>International Journal of Computer Vision<br/>Vol. 108(3), pp. 186-203&nbsp;</td>
	<td>article</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/FLH_IJCV.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Gavves2014" class="entry">
	<td>Gavves, E., Fernando, B., Snoek, C.G., Smeulders, A.W. and Tuytelaars, T.</td>
	<td>Local alignments for fine-grained categorization</td>
	<td>2014</td>
	<td>International Journal of Computer Vision<br/>Vol. 111(2), pp. 191-212&nbsp;</td>
	<td>article</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/IJCV-FG.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2012" class="entry">
	<td>Fernando, B., Fromont, E., Muselet, D. and Sebban, M.</td>
	<td>Supervised learning of Gaussian mixture models for visual vocabulary generation</td>
	<td>2012</td>
	<td>Pattern Recognition<br/>Vol. 45(2), pp. 897-907&nbsp;</td>
	<td>article</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/pr1.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2017book" class="entry">
	<td>Fernando, B., Aljundi, R., Emonet, R., Habrard, A., Sebban, M. and Tuytelaars, T.</td>
	<td>Unsupervised Domain Adaptation Based on Subspace Alignment</td>
	<td>2017</td>
	<td>Domain Adaptation in Computer Vision Applications, pp. 81-94&nbsp;</td>
	<td>inbook</td>
	<td><a href="http://doi.org/10.1007/978-3-319-58347-1_4">DOI</a> <a href="https://doi.org/10.1007/978-3-319-58347-1_4">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2019" class="entry">
	<td>Fernando, B., Tan, C. and Bilen, H.</td>
	<td>Weakly Supervised Gaussian Networks for Action Detection</td>
	<td>2019</td>
	<td>Winter Conference on Applications of Computer Vision (WACV)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://arxiv.org/pdf/1904.07774.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="HerathCVPR19" class="entry">
	<td>Herath, S., Fernando, B., Harandi, M. and Nock, R.</td>
	<td>Min-Max Statistical Alignment for Transfer Learning</td>
	<td>2019</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2019&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Aliakbarian_Encouraging_LSTMs_to_ICCV_2017_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Aliakbarian2018" class="entry">
	<td>Aliakbarian, M.S., Saleh, F., Salzmann, M., Fernando, B., Petersson, L. and Andersson, L.</td>
	<td>VIENA2: A Driving Anticipation Dataset</td>
	<td>2018</td>
	<td>Asian Conference on Computer Vision (ACCV 2018)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://arxiv.org/abs/1810.09044">URL</a>&nbsp;</td>
</tr>
<tr id="Cruz18" class="entry">
	<td>Cruz, R.S., Fernando, B., Cherian, A. and Gould, S.</td>
	<td>Neural Algebra of Classifiers</td>
	<td>2018</td>
	<td>IEEE Winter Conference on Applications of Computer Vision WACV 2018&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://basurafernando.github.io/papers/WACV18_neural_algebra_classifiers.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Rodriguez2018" class="entry">
	<td>Rodriguez, C., Fernando, B. and Li, H.</td>
	<td>Action anticipation by predicting future dynamic images</td>
	<td>2018</td>
	<td>European Conference on Computer Vision, pp. 89-105&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Rodriguez_Action_Anticipation_By_Predicting_Future_Dynamic_Images_ECCVW_2018_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Shi2018" class="entry">
	<td>Shi, Y., Fernando, B. and Hartley, R.</td>
	<td>Action Anticipation with RBF Kernelized Feature Mapping RNN</td>
	<td>2018</td>
	<td>Proceedings of the European Conference on Computer Vision (ECCV), pp. 301-317&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yuge_Shi_Action_Anticipation_with_ECCV_2018_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Yu2018" class="entry">
	<td>Yu, X., Fernando, B. and Hartley, R.</td>
	<td>Super-Resolving Very Low-Resolution Face Images with Supplementary Attributes</td>
	<td>2018</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2018&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Super-Resolving_Very_Low-Resolution_CVPR_2018_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Yu2018a" class="entry">
	<td>Yu, X., Fernando, B., Ghanem, B., Porikli, F. and Hartley, R.</td>
	<td>Face super-resolution guided by facial component heatmaps</td>
	<td>2018</td>
	<td>Proceedings of the European Conference on Computer Vision (ECCV), pp. 217-233&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Xin_Yu_Face_Super-resolution_Guided_ECCV_2018_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Aliakbarian2017" class="entry">
	<td>Aliakbarian, M.S., Saleh, F., Salzmann, M., Fernando, B., Petersson, L. and Andersson, L.</td>
	<td>Encouraging LSTMs to Anticipate Actions Very Early</td>
	<td>2017</td>
	<td>IEEE International Conference on Computer Vision ICCV 2017&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Aliakbarian_Encouraging_LSTMs_to_ICCV_2017_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Anderson2017" class="entry">
	<td>Anderson, P., Fernando, B., Johnson, M. and Gould, S.</td>
	<td>Zero-Shot Image Captioning with Constrained Beam Search</td>
	<td>2017</td>
	<td>Conference on Empirical Methods in Natural Language Processing (EMNLP)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://arxiv.org/abs/1612.00576">URL</a>&nbsp;</td>
</tr>
<tr id="Cherian2017" class="entry">
	<td>Cherian, A., Fernando, B., Harandi, M. and Gould, S.</td>
	<td>Generalized Rank Pooling for Activity Recognition</td>
	<td>2017</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2017&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Cherian_Generalized_Rank_Pooling_CVPR_2017_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Cruz2017" class="entry">
	<td>Cruz, R.S., Fernando, B., Cherian, A. and Gould, S.</td>
	<td>DeepPermNet: Visual Permutation Learning</td>
	<td>2017</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2017&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Santa_Cruz_DeepPermNet_Visual_Permutation_CVPR_2017_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando_2017_CVPR_Workshops" class="entry">
	<td>Fernando, B., Shirazi, S. and Gould, S.</td>
	<td>Unsupervised Human Action Detection by Action Matching</td>
	<td>2017</td>
	<td>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_cvpr_2017_workshops/w20/papers/Fernando_Unsupervised_Human_Action_CVPR_2017_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2017" class="entry">
	<td>Fernando, B., Bilen, H., Gavves, E. and Gould, S.</td>
	<td>Self-Supervised Video Representation Learning With Odd-One-Out Networks</td>
	<td>2017</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2017&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Fernando_Self-Supervised_Video_Representation_CVPR_2017_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Anderson2016" class="entry">
	<td>Anderson, P., Fernando, B., Johnson, M. and Gould, S.</td>
	<td>SPICE: Semantic Propositional Image Caption Evaluation</td>
	<td>2016</td>
	<td>European Conference of Computer Vision 2016 ( ECCV 16)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/ECCV2016Anderson.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Bilen2016" class="entry">
	<td>Bilen, H., Fernando, B., Gavves, E., Vedaldi, A. and Gould, S.</td>
	<td>Dynamic Image Networks for Action Recognition</td>
	<td>2016</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2016&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2016a" class="entry">
	<td>Fernando, B., Anderson, P., Hutter, M. and Gould, S.</td>
	<td>Discriminative Hierarchical Rank Pooling for Activity Recognition</td>
	<td>2016</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2016&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Fernando_Discriminative_Hierarchical_Rank_CVPR_2016_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2016b" class="entry">
	<td>Fernando, B. and Gould, S.</td>
	<td>Learning End-to-end Video Classification with Rank-Pooling</td>
	<td>2016</td>
	<td>International Conference on Machine Learning ICML 2016&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.jmlr.org/proceedings/papers/v48/fernando16.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2015b" class="entry">
	<td>Fernando, B., Gavves, E., Oramas, J., Ghodrati, A. and Tuytelaars, T.</td>
	<td>Modeling video evolution for action recognition</td>
	<td>2015</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2015&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Fernando_Modeling_Video_Evolution_2015_CVPR_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2015c" class="entry">
	<td>Fernando, B., Gavves, E., Muselet, D. and Tuytelaars, T.</td>
	<td>Learning to rank based on subsequences</td>
	<td>2015</td>
	<td>IEEE International Conference on Computer Vision ICCV 2015&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Fernando_Learning_to_Rank_ICCV_2015_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Jia2015" class="entry">
	<td>Jia, X., Gavves, S., Fernando, B. and Tuytelaars, T.</td>
	<td>Guided long-short term memory for image caption generation</td>
	<td>2015</td>
	<td>IEEE International Conference on Computer Vision ICCV 2015&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Jia_Guiding_the_Long-Short_ICCV_2015_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Rematas2015" class="entry">
	<td>Rematas, K., Fernando, B., Dellaert, F. and Tuytelaars, T.</td>
	<td>Dataset Fingerprints: Exploring Image Collections Through Data Mining</td>
	<td>2015</td>
	<td>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition CVPR 2015, pp. 4867-4875&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Rematas_Dataset_Fingerprints_Exploring_2015_CVPR_paper.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2014a" class="entry">
	<td>Fernando, B., Muselet, D., Khan, R. and Tuytelaars, T.</td>
	<td>Color features for dating historical color images</td>
	<td>2014</td>
	<td>IEEE International Conference on Image Processing ICIP 2014&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/ICIP2014.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Aly2013" class="entry">
	<td>Aly, R., Arandjelovic, R., Chatfield, K., Douze, M., Fernando, B., Harchaoui, Z., McGuinness, K., Oâ€™Conner, N.E., Oneata, D., Parkhi, O.M. and others</td>
	<td>The AXES submissions at TrecVid 2013</td>
	<td>2013</td>
	<td>TrecVid&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://hal.inria.fr/docs/00/90/44/04/PDF/axes-tv13-submitted.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Aly2013a" class="entry">
	<td>Aly, R., Arandjelovic, R., Chatfield, K., Douze, M., Fernando, B., Harchaoui, Z., McGuinness, K., O'Connore, N., Oneata, D., Parkhi, O.M. and others</td>
	<td>AXES at TRECVid 2013</td>
	<td>2013</td>
	<td>TRECVid&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://www-nlpir.nist.gov/projects/tvpubs/tv13.papers/axes.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2013" class="entry">
	<td>Fernando, B., Habrard, A., Sebban, M. and Tuytelaars, T.</td>
	<td>Unsupervised Visual Domain Adaptation Using Subspace Alignment</td>
	<td>2013</td>
	<td>IEEE International Conference on Computer Vision ICCV 2013&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/SA_ICCV_2013.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2013a" class="entry">
	<td>Fernando, B. and Tuytelaars, T.</td>
	<td>Mining Multiple Queries for Image Retrieval: On-the-fly learning of an Object-specific Mid-level Representation</td>
	<td>2013</td>
	<td>IEEE International Conference on Computer Vision ICCV 2013&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/MQIR_ICCV_2013.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Gavves2013" class="entry">
	<td>Gavves, E., Fernando, B., Snoek, C., Smeulders, A. and Tuytelaars, T.</td>
	<td>Fine-Grained Categorization by Alignments</td>
	<td>2013</td>
	<td>IEEE International Conference on Computer Vision ICCV 2013&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/FG_ICCV_2013.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Rematas2013" class="entry">
	<td>Rematas, K., Fernando, B., Tommasi, T. and Tuytelaars, T.</td>
	<td>Does Evolution cause a Domain Shift?</td>
	<td>2013</td>
	<td>IEEE International Conference on Computer Vision ICCV 2013 Workshop VisDA&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://homes.esat.kuleuven.be/~krematas/VisDA/main.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Aly2012" class="entry">
	<td>Aly, R., McGuinness, K., Chen, S., O'Connor, N.E., Chatfield, K., Parkhi, O., Arandjelovic, R., Zisserman, A., Fernando, B., Tuytelaars, T. and others</td>
	<td>AXES at TRECVID 2012: KIS, INS, and MED</td>
	<td>2012</td>
	<td>TRECVID&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://doras.dcu.ie/17860/">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2012a" class="entry">
	<td>Fernando, B., Fromont, E., Muselet, D. and Sebban, M.</td>
	<td>Discriminative Feature Fusion for Image Classification</td>
	<td>2012</td>
	<td>IEEE International Conference on Computer Vision and Pattern Recognition CVPR 2012&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/cvpr_2012_lrrf.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2012b" class="entry">
	<td>Fernando, B., Fromont, E. and Tuytelaars, T.</td>
	<td>Effective Use of Frequent Itemset Mining for Image Classification</td>
	<td>2012</td>
	<td>European Conference of Computer Vision 2012 ( ECCV 12)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://users.cecs.anu.edu.au/~basura/papers/ECCV_ID10.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Moreno2011" class="entry">
	<td>Moreno, A., Fernando, B., Kani, B., Saha, S. and Karaoglu, S.</td>
	<td>Color correction: a novel weighted Von Kries model based on memory colors</td>
	<td>2011</td>
	<td>Computational Color Imaging, pp. 165-175&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://staff.fnwi.uva.nl/s.karaoglu/ColorCorrection.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Tremeau2011" class="entry">
	<td>Tr&eacute;meau, A., Fernando, B., Karaoglu, S. and Muselet, D.</td>
	<td>Text segmentation in natural images robust to photometric effects</td>
	<td>2011</td>
	<td>AIC midterm meeting, pp. 86-89&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://hal.archives-ouvertes.fr/ujm-00629475/">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2010" class="entry">
	<td>Fernando, B., Karaoglu, S. and Tr&eacute;meau, A.</td>
	<td>Extreme Value Theory Based Text Binarization in Documents and Natural Scenes</td>
	<td>2010</td>
	<td>International Conference on Machine Vision&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://staff.science.uva.nl/~sezerk/EXTREME.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Fernando2010a" class="entry">
	<td>Fernando, B., Fromont, E., Muselet, D. and Sebban, M.</td>
	<td>Accurate Visual Word Construction using a Supervised Approach</td>
	<td>2010</td>
	<td>25th International Conference of Image and Vision Computing New Zealand, New Zealand (2010), pp. 1-7&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://hal.archives-ouvertes.fr/hal-00555639/document">URL</a>&nbsp;</td>
</tr>
<tr id="Karaoglu2010" class="entry">
	<td>Karaoglu, S., Fernando, B. and Tr&eacute;meau, A.</td>
	<td>A novel algorithm for text detection and localization in natural scene images</td>
	<td>2010</td>
	<td>Digital Image Computing: Techniques and Applications (DICTA), 2010 International Conference on, pp. 635-642&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://staff.fnwi.uva.nl/s.karaoglu/DICTA.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="Gould2016a" class="entry">
	<td>Gould, S., Fernando, B., Cherian, A., Anderson, P., Cruz, R.S. and Guo, E.</td>
	<td>On Differentiating Parameterized Argmin and Argmax Problems with Application to Bi-level Optimization</td>
	<td>2016</td>
	<td>&nbsp;</td>
	<td>unpublished</td>
	<td><a href="http://arxiv.org/abs/1607.05447">URL</a>&nbsp;</td>
</tr>
<tr id="fernando2014subspace" class="entry">
	<td>Fernando, B., Habrard, A., Sebban, M. and Tuytelaars, T.</td>
	<td>Subspace alignment for domain adaptation</td>
	<td>2014</td>
	<td>&nbsp;</td>
	<td>unpublished</td>
	<td><a href="https://arxiv.org/abs/1409.5241">URL</a>&nbsp;</td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 05/12/2019.</small>
</footer>

<!-- file generated by JabRef -->

</body>
</html>